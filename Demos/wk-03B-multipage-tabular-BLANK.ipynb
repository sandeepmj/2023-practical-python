{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[{"file_id":"133K0NfwJ7esE3C-1QJ87ioTys44QdCLg","timestamp":1686746316714},{"file_id":"1LoyGXck4gm9F5OCk8k8YnltY-qlS7IR2","timestamp":1686738505513},{"file_id":"19JXSG8YXI8ZeNhzg8eaosuUkNaOp0xul","timestamp":1649162440933},{"file_id":"1KakOxScjK7egFn3ooKIf7Rb6ZUXqQgxK","timestamp":1645576583652},{"file_id":"1z2FLWwyi08NbTWdTLDEvMFbVIUWVuA7P","timestamp":1627431398775},{"file_id":"1VYOVnnddMwivH0B0hVpZswz7cKoEAfh-","timestamp":1627392451278},{"file_id":"1l6IbXo8xXwYbyNHHaNoH7QP3ssh_xrKq","timestamp":1619610819329}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1rg5ypHYQ2vB"},"source":["# Multi-page Tables Scrape Demo\n","\n","You're often going to encounter data and tables spread across hundreds if not thousands of pages."]},{"cell_type":"markdown","source":["We might want to, for example, compile details about all the doctors  <a href=\"https://apps.health.ny.gov/pubdoh/professionals/doctors/conduct/factions/AllRecordsAction.action\">on this site</a> and export to a ```dataframe``` and a ```.csv``` file."],"metadata":{"id":"JLy-Ml41_-Zd"}},{"cell_type":"markdown","metadata":{"id":"2FAa4EkaQ2vH"},"source":["#### Today in class\n","\n","We're going to scrape as a demo a table that runs across several pages on [this mock website](https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html).\n","\n","```https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html```"]},{"cell_type":"markdown","metadata":{"id":"DTY4tDkVQ2vI"},"source":["To capture your target information into a single CSV file will require the use of many of the foundational skills we've covered, including:\n","\n","- ```delays```\n","- ```conditional logic```\n","- ```for loops```\n","\n","\n","And we'll explore a few new functional Python methods today."]},{"cell_type":"markdown","metadata":{"id":"zzHxjNFUQ2vI"},"source":["## Scraping Strategies\n","\n","- How do we approach this scrape?\n","- What pattern do we see?\n","- How do we capture a table on a single page?\n","- How do we capture a sequence of tables?\n","- How we navigate from page 1 to the subsequent pages?"]},{"cell_type":"markdown","metadata":{"id":"f9IgexKhQ2vJ"},"source":["# Let's code!"]},{"cell_type":"code","metadata":{"id":"tZ7ZNO8YQ2vJ"},"source":["# import libraries\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wl2yMzxEQ2vK"},"source":["## Single Table Scrape"]},{"cell_type":"code","metadata":{"id":"L3eCtCpJQ2vK"},"source":["##scrape url website"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PShccOFp4Xg7"},"source":["## page content type\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEbE38UkHkxb"},"source":["## page text type\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lq7Fxh77KLU8"},"source":["## ```Pandas``` captures tables.\n"]},{"cell_type":"code","metadata":{"id":"gh83GGbyQ2vL"},"source":["## use Pandas to read tables on page\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvtGiiY7Q2vL"},"source":["## Do we want the first table?\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXIYAPPqQ2vL"},"source":["## store it into a copy called animals_df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gheKHsbiQ2vM"},"source":["## But we want to scrape multiple pages\n"]},{"cell_type":"code","metadata":{"id":"euCu3yvc6GsF"},"source":["## Never do this manually\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ```f-strings``` to create our links"],"metadata":{"id":"46_dtNz43Cb8"}},{"cell_type":"code","metadata":{"id":"e8hJx1nSQ2vO"},"source":["## base url of site to scrape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGQMfxyrQ2vO"},"source":["## Using a ```for loop```\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WbAbHYLVcfX"},"source":["## using list comprehension\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_oDySdwQ2vO"},"source":["## Back to our scrape\n","\n","Remember, we'll hit this server too fast. We have to add a delay."]},{"cell_type":"code","metadata":{"id":"RyDiu5HVQ2vQ"},"source":["## Let's import the required libaries to create a delay\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## first time scrape\n","\n"],"metadata":{"id":"4_Pl33BnuGck"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## what was our status code when it broke?\n"],"metadata":{"id":"25AH8Ema5FT9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0uPWDrxJQ2vQ"},"source":["## Working Around Errors\n","\n","When you scrape hundreds of pages, there's chance that one of the URLs might be a dud.\n","\n","We can set up a error control to see what kind of responses we get:\n","\n","```<Response [200]>``` means website is accessible.\n","\n","```<Response [404]>``` means broken link or no page on content.\n","\n","In that case, your whole code might break and you'll have to figure out where it broke.\n","\n","We can make that easier with ```Conditional Logic``` or ```Error Exceptions```"]},{"cell_type":"markdown","source":["### Bypassing exceptions"],"metadata":{"id":"CO50-gA84tMe"}},{"cell_type":"code","source":["## deal with exceptions\n","## hold on to broken links\n"],"metadata":{"id":"25bbP3YKvYQy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## which link broke?\n"],"metadata":{"id":"DQ1-n--sQH9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## what does df_all hold?\n"],"metadata":{"id":"a_qXuB6dQkWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## convert to a single df rather than a list of df\n"],"metadata":{"id":"cadFBbKfxoGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## export to csv\n"],"metadata":{"id":"AsXNgC9G56a1"},"execution_count":null,"outputs":[]}]}