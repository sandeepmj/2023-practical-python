{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja871rAui_Da"
   },
   "source": [
    "# Scraping Files from Websites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwHrS-KJi_Dg"
   },
   "source": [
    "### You need to create a data set that tracks how many companies the <a href=\"https://www.sec.gov/litigation/suspensions.shtml\">SEC suspended</a> between 2019 and 1999. You find the data at:\n",
    "\n",
    "```https://www.sec.gov/litigation/suspensions.shtml```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_OAOaqLi_Dh"
   },
   "source": [
    "### We want to write a scraper that aggregates:\n",
    "\n",
    "* Date of suspension\n",
    "* Company name\n",
    "* Order\n",
    "* Release (the PDFs in the XX-YYYYY format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECK4Q7IOi_Di"
   },
   "source": [
    "# The Challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQj34GvYi_Di"
   },
   "source": [
    "### Details are actually in PDFs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfkXDlQvi_Di"
   },
   "source": [
    "# Demo downloading files from websites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvf5HLGi_Dj"
   },
   "source": [
    "There are ```txt``` and ```pdf``` files on:\n",
    "\n",
    "```https://sandeepmj.github.io/scrape-example-page/pages.html```\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1. Download all ```txt``` files.\n",
    "2. Download all ```pdf``` files.\n",
    "3. Download all files as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W1jQ2nQei_Dj"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests ## get web pages from server\n",
    "import time # time is required. we will use its sleep function\n",
    "from random import randrange # generate random numbers\n",
    "\n",
    "# from google.colab import files ## code for downloading in google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to handle our initial requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write function here\n",
    "def mk_request(url):\n",
    "    '''\n",
    "    Takes a provided url and returns requested response\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    if 200 <= response.status_code < 400:\n",
    "        return response\n",
    "    else:\n",
    "        print(f\"request returned {response.status_code} error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cV7Mwt-Ai_Dk"
   },
   "outputs": [],
   "source": [
    "# url to scrape\n",
    "myurl = \"https://sandeepmj.github.io/scrape-example-page/pages.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the function\n",
    "response = mk_request(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyHHqpmYi_Dk"
   },
   "source": [
    "## Turn page into soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create function to create soup\n",
    "def mk_soup(response):\n",
    "    '''\n",
    "    Make soup\n",
    "    '''\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MC function\n",
    "def scraper(url):\n",
    "    '''\n",
    "    enter url, to return soup of page\n",
    "    '''\n",
    "    return mk_soup(mk_request(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\">\n",
       "<head>\n",
       "<!-- Makes the page responsive and scaled to be read easily -->\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- Links to stylesheet -->\n",
       "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<!-- Remember to update page title -->\n",
       "<title>List of Documents</title>\n",
       "</head>\n",
       "<body>\n",
       "<!-- All content goes here -->\n",
       "<div class=\"container\">\n",
       "<h1>Documents to Download</h1>\n",
       "<li>Junk Li <a href=\"\">tag 1</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 2</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this first set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 3</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 4</a></li>\n",
       "<ul class=\"pdfs downloadable\">\n",
       "<p class=\"pages\">Download this list of PDFs</p>\n",
       "<li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>\n",
       "<li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 5</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 6</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this second set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = scraper(myurl)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\">\n",
       "<head>\n",
       "<!-- Makes the page responsive and scaled to be read easily -->\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- Links to stylesheet -->\n",
       "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<!-- Remember to update page title -->\n",
       "<title>List of Documents</title>\n",
       "</head>\n",
       "<body>\n",
       "<!-- All content goes here -->\n",
       "<div class=\"container\">\n",
       "<h1>Documents to Download</h1>\n",
       "<li>Junk Li <a href=\"\">tag 1</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 2</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this first set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 3</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 4</a></li>\n",
       "<ul class=\"pdfs downloadable\">\n",
       "<p class=\"pages\">Download this list of PDFs</p>\n",
       "<li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>\n",
       "<li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 5</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 6</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this second set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call the function\n",
    "soup = mk_soup(response)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z42CN1eKi_Dk"
   },
   "source": [
    "## Find all txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "l5GhvRuji_Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save in list called txt_holder\n",
    "aTags = soup.find(\"ul\", class_=\"txts\").find_all(\"a\")\n",
    "aTags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8sCo7syi_Dl"
   },
   "source": [
    "## Find all the ```a``` tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BBjQWqsi_Dl"
   },
   "outputs": [],
   "source": [
    "## target a tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UPgFpi0ui_Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/files/text_doc_01.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_02.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_03.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_04.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_05.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_06.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_07.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_08.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_09.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_10.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save without html using for loop\n",
    "links = [base_url + atag.get(\"href\") for atag in aTags]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save without html using list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Sv-zUhi_Dm"
   },
   "source": [
    "## What is missing from the URLs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BR4K5BkGi_Dm"
   },
   "outputs": [],
   "source": [
    "## base url\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8sgMa05i_Dm"
   },
   "source": [
    "## Create a list of the full URLs\n",
    "\n",
    "Without all the ```html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOJEvd2ki_Dm"
   },
   "outputs": [],
   "source": [
    "## lc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCqmE0y6i_Dm"
   },
   "source": [
    "## Download all the ```txt``` documents\n",
    "\n",
    "pip install wget, a great utility to download from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/sandeepjunnarkar/opt/anaconda3/lib/python3.9/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zUM7ToNEi_Dn"
   },
   "outputs": [],
   "source": [
    "## import wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make timer function\n",
    "def snoozer(start_range, end_range):\n",
    "    snooze_time = randrange(start_range, end_range)\n",
    "    print(f\"\\n Snoozing for {snooze_time} seconds\")\n",
    "    return time.sleep(snooze_time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Snoozing for 13 seconds\n"
     ]
    }
   ],
   "source": [
    "snoozer(10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 10\n",
      "100% [................................................................] 76 / 76\n",
      " Snoozing for 16 seconds\n",
      "Downloading link 2 of 10\n",
      "100% [................................................................] 66 / 66\n",
      " Snoozing for 13 seconds\n",
      "Downloading link 3 of 10\n",
      "100% [................................................................] 70 / 70\n",
      " Snoozing for 12 seconds\n",
      "Downloading link 4 of 10\n",
      "100% [................................................................] 63 / 63\n",
      " Snoozing for 19 seconds\n",
      "Downloading link 5 of 10\n",
      "100% [................................................................] 66 / 66\n",
      " Snoozing for 12 seconds\n",
      "Downloading link 6 of 10\n",
      "100% [................................................................] 66 / 66\n",
      " Snoozing for 17 seconds\n",
      "Downloading link 7 of 10\n",
      "100% [................................................................] 69 / 69\n",
      " Snoozing for 19 seconds\n",
      "Downloading link 8 of 10\n",
      "100% [................................................................] 65 / 65\n",
      " Snoozing for 15 seconds\n",
      "Downloading link 9 of 10\n",
      "100% [................................................................] 66 / 66\n",
      " Snoozing for 10 seconds\n",
      "Downloading link 10 of 10\n",
      "100% [................................................................] 60 / 60\n",
      " Snoozing for 13 seconds\n"
     ]
    }
   ],
   "source": [
    "## download with timer\n",
    "\n",
    "link_count = 1\n",
    "start_range, end_range = 10, 21\n",
    "for link in links:\n",
    "    print(f\"Downloading link {link_count} of {len(links)}\")\n",
    "    link_count += 1\n",
    "    wget.download(link)\n",
    "    snoozer(start_range, end_range)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find all text docs on page\n",
    "all_text = soup.find_all(\"ul\", class_=\"txts\")\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"files/text_doc_01.txt\">1</a>, <a href=\"files/text_doc_02.txt\">2</a>, <a href=\"files/text_doc_03.txt\">3</a>, <a href=\"files/text_doc_04.txt\">4</a>, <a href=\"files/text_doc_05.txt\">5</a>, <a href=\"files/text_doc_06.txt\">6</a>, <a href=\"files/text_doc_07.txt\">7</a>, <a href=\"files/text_doc_08.txt\">8</a>, <a href=\"files/text_doc_09.txt\">9</a>, <a href=\"files/text_doc_10.txt\">10</a>]\n",
      "******\n",
      "[<a href=\"files/text_doc_A.txt\">1</a>, <a href=\"files/text_doc_B.txt\">2</a>, <a href=\"files/text_doc_C.txt\">3</a>, <a href=\"files/text_doc_D.txt\">4</a>, <a href=\"files/text_doc_E.txt\">5</a>, <a href=\"files/text_doc_F.txt\">6</a>, <a href=\"files/text_doc_G.txt\">7</a>, <a href=\"files/text_doc_H.txt\">8</a>, <a href=\"files/text_doc_I.txt\">9</a>, <a href=\"files/text_doc_J.txt\">10</a>]\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "atag_list = []\n",
    "for atag in all_text:\n",
    "    atag_list.append(atag.find_all(\"a\"))\n",
    "    print(atag.find_all(\"a\"))\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_links = list(itertools.chain(*atag_list))\n",
    "html_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "week-7-download_docs_BLANK.ipynb",
   "provenance": [
    {
     "file_id": "1nqLLwMBVA4UJus95SFvmBL-GsFXxpcsW",
     "timestamp": 1638974922793
    },
    {
     "file_id": "1J1lhUQakLF4NmWxBeEGiprUMSv1j7cpk",
     "timestamp": 1628019785208
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
